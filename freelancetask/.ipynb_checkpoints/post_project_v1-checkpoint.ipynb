{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o_data = pd.read_excel(r'Post_detction_Task_cpie.xlsx',encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o_data.drop(o_data.index[[1326,24652,53921]], inplace=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeSeriesData=pd.DataFrame()\n",
    "timeSeriesData['date']=o_data['Created Time']\n",
    "timeSeriesData['totalreactions']=o_data['Reaction Count']\n",
    "timeSeriesData['Share Count']=o_data['Share Count']\n",
    "timeSeriesData['Comment Count']=o_data['Comment Count']\n",
    "timeSeriesData1 = timeSeriesData.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timeSeriesData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "totalCount=[]\n",
    "month=[]\n",
    "for i in timeSeriesData1.index :\n",
    "    print(i)\n",
    "    \n",
    "    if type(timeSeriesData1['date'][i])==str and timeSeriesData1['totalreactions'][i]> 0:\n",
    "        match = re.search('\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}', timeSeriesData1['date'][i])\n",
    "        month.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').month)\n",
    "        date.append(timeSeriesData1['date'][i])\n",
    "        share=timeSeriesData1['Share Count'][i]\n",
    "        comment=timeSeriesData1['Comment Count'][i]\n",
    "        total=timeSeriesData1['totalreactions'][i]\n",
    "        if(math.isnan(share)):\n",
    "            share=0\n",
    "        \n",
    "        if(math.isnan(comment)):\n",
    "            comment=0\n",
    "        \n",
    "        if(math.isnan(total)):\n",
    "            total=0\n",
    "        \n",
    "        totalCount.append(share+comment+total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_Data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_Data['date']=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_Data['totalCount']=totalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_Data.apply(lambda s: pd.datetime.strptime(s['date'], '%Y-%m-%d-%H:%M:%S') , axis=1).rename('date').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDataDate=new_Data.groupby('date')['totalCount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#newDataDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(newDataDate.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from statsmodels.graphics.tsaplots import plot_acf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#series=newDataDate\n",
    "#plot_acf(series, lags=31)\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pandas import Series\n",
    "# from pandas import DataFrame\n",
    "# from pandas import concat\n",
    "# from matplotlib import pyplot\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# #series = Series.from_csv('daily-minimum-temperatures.csv', header=0)\n",
    "# # create lagged dataset\n",
    "# values = DataFrame(series.values)\n",
    "# dataframe = concat([values.shift(1), values], axis=1)\n",
    "# dataframe.columns = ['t-1', 't+1']\n",
    "# # split into train and test sets\n",
    "# X = dataframe.values\n",
    "# train, test = X[1:len(X)-7], X[len(X)-7:]\n",
    "# train_X, train_y = train[:,0], train[:,1]\n",
    "# test_X, test_y = test[:,0], test[:,1]\n",
    " \n",
    "# # persistence model\n",
    "# def model_persistence(x):\n",
    "# \treturn x\n",
    " \n",
    "# # walk-forward validation\n",
    "# predictions = list()\n",
    "# for x in test_X:\n",
    "# \tyhat = model_persistence(x)\n",
    "# \tpredictions.append(yhat)\n",
    "# test_score = mean_squared_error(test_y, predictions)\n",
    "# print('Test MSE: %.3f' % test_score)\n",
    "# # plot predictions vs expected\n",
    "# pyplot.plot(test_y)\n",
    "# pyplot.plot(predictions, color='red')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pandas import Series\n",
    "# from matplotlib import pyplot\n",
    "# from statsmodels.tsa.ar_model import AR\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# #series = Series.from_csv('daily-minimum-temperatures.csv', header=0)\n",
    "# # split dataset\n",
    "# X = series.values\n",
    "# train, test = X[1:len(X)-7], X[len(X)-7:]\n",
    "# # train autoregression\n",
    "# model = AR(train)\n",
    "# model_fit = model.fit()\n",
    "# print('Lag: %s' % model_fit.k_ar)\n",
    "# print('Coefficients: %s' % model_fit.params)\n",
    "# # make predictions\n",
    "# predictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)\n",
    "# for i in range(len(predictions)):\n",
    "# \tprint('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
    "# error = mean_squared_error(test, predictions)\n",
    "# print('Test MSE: %.3f' % error)\n",
    "# # plot results\n",
    "# pyplot.plot(test)\n",
    "# pyplot.plot(predictions, color='red')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'out1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.drop('Unnamed: 0', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#model = Prophet()\n",
    "#model.fit(df);\n",
    "model = pickle.load(open('model.sav', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting best hours in next 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=72, freq = 'h')\n",
    "future.tail(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forecast = model.predict(future.tail(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(forecast, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast = pickle.load(open('predec_model.sav', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ans_hourly=result.sort_values(by='yhat', ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best 5 hours in next 3 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_hourly['ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# month=[]\n",
    "# day=[]\n",
    "# hour=[]\n",
    "# year=[]\n",
    "\n",
    "# for i in ans_hourly.index:\n",
    "#         convert=datetime.strftime(ans_hourly['ds'][i], \"%Y-%m-%d-%H:%M:%S\")\n",
    "#         match = re.search('\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}', convert)\n",
    "#         year.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').year)\n",
    "#         month.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').month)\n",
    "#         day.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').day)\n",
    "#         hour.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "future_day = model.make_future_dataframe(periods=30, freq = 'd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast_day = pickle.load(open('predec_model_day.sav', 'rb'))\n",
    "#forecast_day = model.predict(future_day)\n",
    "result_day=forecast_day[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ans_day=result_day.sort_values(by='yhat', ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best 5 days for this month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_day['ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_week = model.make_future_dataframe(periods=30, freq = 'w')\n",
    "future_week.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forecast_week = model.predict(future_week)\n",
    "forecast_week = pickle.load(open('predec_model_weekly.sav', 'rb'))\n",
    "result_week=forecast_week[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans_week=result_week.sort_values(by='yhat', ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best week for current month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_week['ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# month=[]\n",
    "# day=[]\n",
    "# hour=[]\n",
    "# year=[]\n",
    "\n",
    "# for i in ans_day.index:\n",
    "#         convert=datetime.strftime(ans_day['ds'][i], \"%Y-%m-%d-%H:%M:%S\")\n",
    "#         match = re.search('\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}', convert)\n",
    "#         year.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').year)\n",
    "#         month.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').month)\n",
    "#         day.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').day)\n",
    "#         hour.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# month=[]\n",
    "# day=[]\n",
    "# hour=[]\n",
    "# year=[]\n",
    "\n",
    "# for i in ans_week.index:\n",
    "#         convert=datetime.strftime(ans_week['ds'][i], \"%Y-%m-%d-%H:%M:%S\")\n",
    "#         match = re.search('\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}', convert)\n",
    "#         year.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').year)\n",
    "#         month.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').month)\n",
    "#         day.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').day)\n",
    "#         hour.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('arabic'))\n",
    "stop1=set(stopwords.words('french'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    if type(doc) is str:\n",
    "        stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    else :\n",
    "        normalized=doc\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_array=[]\n",
    "sentence_len=[]\n",
    "for i in o_data.index:\n",
    "    print(i)\n",
    "    if type(o_data['Message'][i]) is str:\n",
    "        split=clean(o_data['Message'][i]).split()\n",
    "        w_array.append(split)\n",
    "        sentence_len.append(len(split))\n",
    "    else:\n",
    "        w_array.append('a')\n",
    "        sentence_len.append(0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(w_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o_data['words']=w_array\n",
    "o_data['sen_len']=sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o_data['total_count']=o_data['Reaction Count']+o_data['Share Count']+o_data['Comment Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over all running sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "o_data.sort_values(by='total_count', ascending=False).head(10)['Sector'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding lengh on content Over All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_data.sort_values(by='total_count', ascending=False).head(10)['sen_len'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best content lenght sector wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can replace the any sector value from Media \n",
    "\n",
    "best_content=o_data.loc[o_data['Sector']=='Media'].sort_values(by='total_count', ascending=False).head(10)['sen_len'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best content range is : ' + str(min(best_content)) + ' to ' + str(max(best_content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best content length with sector and month wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "totalCount=[]\n",
    "month=[]\n",
    "day=[]\n",
    "for i in o_data.index :\n",
    "    print(i)\n",
    "    \n",
    "    if type(o_data['Created Time'][i])==str  :\n",
    "        match = re.search('\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}', o_data['Created Time'][i])\n",
    "        month.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').month)\n",
    "        day.append(datetime.strptime(match.group(), '%Y-%m-%d-%H:%M:%S').day)\n",
    "    else:\n",
    "        \n",
    "        month.append(0)\n",
    "        day.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o_data['month']=month\n",
    "o_data['day']=day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can enter any sector value from Media place and any month value from 12 place\n",
    "\n",
    "best_content=o_data.loc[o_data['Sector']=='Media']\n",
    "best_content.loc[best_content['month']==12].sort_values(by='total_count', ascending=False).head(10)['sen_len'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Sector monthly wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can replace any month value from 1\n",
    "\n",
    "best_content=o_data.loc[o_data['month']==1].sort_values(by='total_count', ascending=False).head(10)['Sector'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Sector day Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#you can replace any day value from 15\n",
    "best_content=o_data.loc[o_data['day']==15].sort_values(by='total_count', ascending=False).head(10)['Sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
